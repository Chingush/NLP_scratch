{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0c2ca1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "  def __init__(self, texts, targets, tokenizer, max_len=512):\n",
    "    self.texts = texts\n",
    "    self.targets = targets\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.texts)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    text = str(self.texts[idx])\n",
    "    target = self.targets[idx]\n",
    "\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=self.max_len,\n",
    "        return_token_type_ids=False,\n",
    "        padding='max_length',\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    return {\n",
    "      'text': text,\n",
    "      'input_ids': encoding['input_ids'].flatten(),\n",
    "      'attention_mask': encoding['attention_mask'].flatten(),\n",
    "      'targets': torch.tensor(target, dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bc7265",
   "metadata": {},
   "source": [
    "!pip install transformers\n",
    "!pip install --upgrade huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "380d8cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer_path = 'cointegrated/rubert-tiny'\n",
    "tokenizer = BertTokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1f759d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "model_path = 'cointegrated/rubert-tiny'\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3be74358",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_features = model.bert.encoder.layer[1].output.dense.out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "04d7e559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312\n"
     ]
    }
   ],
   "source": [
    "print(out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0ae6d2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier = torch.nn.Linear(312, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "eae39a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "#from bert_dataset import CustomDataset\n",
    "\n",
    "class BertClassifier:\n",
    "\n",
    "    def __init__(self, model_path, tokenizer_path, n_classes=3, epochs=10, model_save_path='/content/bert.pt'):\n",
    "        self.model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.device = \"cpu\"\n",
    "        self.model_save_path=model_save_path\n",
    "        self.max_len = 512\n",
    "        self.epochs = epochs\n",
    "        self.out_features = self.model.bert.encoder.layer[1].output.dense.out_features\n",
    "        self.model.classifier = torch.nn.Linear(self.out_features, n_classes)\n",
    "        self.model.to(self.device)\n",
    "    \n",
    "    def preparation(self, X_train, y_train, X_valid, y_valid):\n",
    "        # create datasets\n",
    "        self.train_set = CustomDataset(X_train, y_train, self.tokenizer)\n",
    "        self.valid_set = CustomDataset(X_valid, y_valid, self.tokenizer)\n",
    "\n",
    "        # create data loaders\n",
    "        self.train_loader = DataLoader(self.train_set, batch_size=2, shuffle=True)\n",
    "        self.valid_loader = DataLoader(self.valid_set, batch_size=2, shuffle=True)\n",
    "\n",
    "        # helpers initialization\n",
    "        self.optimizer = AdamW(self.model.parameters(), lr=2e-5, correct_bias=False)\n",
    "        self.scheduler = get_linear_schedule_with_warmup(\n",
    "                self.optimizer,\n",
    "                num_warmup_steps=0,\n",
    "                num_training_steps=len(self.train_loader) * self.epochs\n",
    "            )\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss().to(self.device)\n",
    "            \n",
    "    def fit(self):\n",
    "        self.model = self.model.train()\n",
    "        losses = []\n",
    "        correct_predictions = 0\n",
    "\n",
    "        for data in self.train_loader:\n",
    "            input_ids = data[\"input_ids\"].to(self.device)\n",
    "            attention_mask = data[\"attention_mask\"].to(self.device)\n",
    "            targets = data[\"targets\"].to(self.device)\n",
    "\n",
    "            outputs = self.model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "                )\n",
    "\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            loss = self.loss_fn(outputs.logits, targets)\n",
    "\n",
    "            correct_predictions += torch.sum(preds == targets)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "        train_acc = correct_predictions.double() / len(self.train_set)\n",
    "        train_loss = np.mean(losses)\n",
    "        return train_acc, train_loss\n",
    "    \n",
    "    def eval(self):\n",
    "        self.model = self.model.eval()\n",
    "        losses = []\n",
    "        correct_predictions = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in self.valid_loader:\n",
    "                input_ids = data[\"input_ids\"].to(self.device)\n",
    "                attention_mask = data[\"attention_mask\"].to(self.device)\n",
    "                targets = data[\"targets\"].to(self.device)\n",
    "\n",
    "                outputs = self.model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask\n",
    "                    )\n",
    "\n",
    "                preds = torch.argmax(outputs.logits, dim=1)\n",
    "                loss = self.loss_fn(outputs.logits, targets)\n",
    "                correct_predictions += torch.sum(preds == targets)\n",
    "                losses.append(loss.item())\n",
    "        \n",
    "        val_acc = correct_predictions.double() / len(self.valid_set)\n",
    "        val_loss = np.mean(losses)\n",
    "        return val_acc, val_loss\n",
    "    \n",
    "    def train(self):\n",
    "        best_accuracy = 0\n",
    "        for epoch in range(self.epochs):\n",
    "            print(f'Epoch {epoch + 1}/{self.epochs}')\n",
    "            train_acc, train_loss = self.fit()\n",
    "            print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "            val_acc, val_loss = self.eval()\n",
    "            print(f'Val loss {val_loss} accuracy {val_acc}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            if val_acc > best_accuracy:\n",
    "                torch.save(self.model, self.model_save_path)\n",
    "                best_accuracy = val_acc\n",
    "\n",
    "        self.model = torch.load(self.model_save_path)\n",
    "    \n",
    "    def predict(self, text):\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        out = {\n",
    "              'text': text,\n",
    "              'input_ids': encoding['input_ids'].flatten(),\n",
    "              'attention_mask': encoding['attention_mask'].flatten()\n",
    "          }\n",
    "        \n",
    "        input_ids = out[\"input_ids\"].to(self.device)\n",
    "        attention_mask = out[\"attention_mask\"].to(self.device)\n",
    "        \n",
    "        outputs = self.model(\n",
    "            input_ids=input_ids.unsqueeze(0),\n",
    "            attention_mask=attention_mask.unsqueeze(0)\n",
    "        )\n",
    "        \n",
    "        prediction = torch.argmax(outputs.logits, dim=1).cpu().numpy()[0]\n",
    "\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "56d78b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(sentiment):\n",
    "    if sentiment == -1:\n",
    "        return 0\n",
    "    elif sentiment == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def remove_url(text): \n",
    "    url_pattern  = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    return url_pattern.sub(r'', text)\n",
    " # converting return value from list to string\n",
    "\n",
    "\n",
    "\n",
    "def clean_text(text ): \n",
    "    delete_dict = {sp_character: '' for sp_character in string.punctuation} \n",
    "    delete_dict[' '] = ' ' \n",
    "    table = str.maketrans(delete_dict)\n",
    "    text1 = text.translate(table)\n",
    "    #print('cleaned:'+text1)\n",
    "    textArr= text1.split()\n",
    "    text2 = ' '.join([w for w in textArr if ( not w.isdigit() and  ( not w.isdigit() and len(w)>2))]) \n",
    "    \n",
    "    return text2.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "53702aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Train data--------\n",
      "news\n",
      " !Пожилого уфимца, отсидевшего за чужое преступление 13 лет, реабилитировали Фатхулла Исхаков отсидел 13 лет за чужое преступление и полвека добивался оправдания. Как сообщается в группе телепроекта [club187046624|ЧЕСТНО ГОВОРЯ | новости Уфы и Башкирии], впервые в истории страны дело с истёкшей 50 лет назад исковой давностью сначала было передано в Шестой кассационный суд, а затем и в Верховный суд России. Решение об отмене приговора 1959 года принял сегодня Верховный суд Российской Федерации. Конституционный суд России 21 декабря 2021 года разрешил судам в отдельных особых случаях пересматривать приговоры по новым обстоятельствам вопреки позиции прокурора. Соответствующее постановление в ответ на жалобу осужденного в 1959 году жителя Уфы Фатхуллы Исхакова опубликовали на официальном сайте суда. Уфимец был приговорен к лишению свободы по обвинению в покушении на убийство. 13 лет он провел в колонии. Мужчина утверждал, что ни в чем не виноват, и после освобождения десятки лет добивался отмены приговора. В 2012 году один из свидетелей признался в совершении преступления, за которое был осужден Исхаков. Много лет сохраняется неясность этого дела: прокуратура неоднократно прекращала его производство, суды по жалобам добивающегося реабилитации Исхакова с ней не соглашались, но и приговор заявителя не отменяли до сегодняшнего дня.    2\n",
      " Эльмира Диваева из Башкирии вышла в финал телешоу «Голос» Наша землячка Эльмира Диваева вышла в финала телешоу «Голос», сообщает Башинформ. Уроженка Стерлитамака исполнила песню «А на море белый песок» из репертура Жанны Фриске. Эльмира обошла соперниц из тройки своего наставника Владимира Преснякова еще на этапе зрительского голосования. Сам наставник также отдал ей половину своих голосов. Соперницами Эльмиры были Алина Бахшалиева из Саратова и Маргарита Багдасарян из Сочи.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      2\n",
      " Сотрудники ГИБДД Башкирии на трассе помогли дальнобойщику заменить колесо у большегруза Сотрудники ГИБДД Башкирии на федеральной трассе помогли дальнобойщику заменить колесо у большегруза. Как сообщили «Башинформу» в пресс-службе ведомства, во время профилактических мероприятий в Дюртюлинском районе на 1230 км М-7 «Волга» при объезде маршрута патрулирования автоинспекторы увидели стоящий на дороге большегруз Sitrak с проколотым задним колесом. «Сотрудники ГИБДД обеспечили безопасный проезд для других автомобилей, а затем помогли водителю заменить колесо. Автомобилист поблагодарил автоинспекторов за оказанную помощь, отметив, что он самостоятельно не справился бы», — подчеркнули в ведомстве.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          2\n",
      " Боец из Башкирии отдал свою жизнь ради победы над нацизмом Защитники Отечества выполняют важнейшую задачу и заслуживают, чтобы о них знала наша страна. Ефрейтор Данил Саматович Фаттахов — герой специальной военной операции. Боец родился 9 марта 1985 года. 2003 году окончил среднюю школу в Уфе. Затем проходил военную службу по призыву в войсках МЧС. Поступил в московский институт, одновременно работал водителем в полиции. 25 мая 2022 года заключил контракт на прохождение военной службы. 26 июня 2022 года героически погиб на территории Украины. Данил Саматович Фаттахов отдал свою жизнь ради победы над нацизмом. За мужество, отвагу и самоотверженность награжден орденом Мужества (посмертно).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             2\n",
      " «Обстановка только ухудшится»: Глава МЧС по Башкирии призвал граждан исключить разведение костров Начальник МЧС по Башкирии Марат Латыпов 11 июля на встрече с журналистами в ИА «Башинформ» сообщил о том, что в ближайшее время ситуация с пожарами в регионе может ухудшиться, так как прогнозируется усиление ветра, в частности, сегодня днем местами по республике ожидаются шквалистые порывы до 23-28 м/с. ??«Обстановка только ухудшится. Обращаюсь к жителям Башкирии! Исключите разведение костров, все, что подразумевает разведение огня. Нам и гроз хватает, которые провоцируют возгорания», — сказал Марат Латыпов. По его словам, за сутки зарегистрирован один очаг лесного пожара на площади 19,8 га в Гафурийском районе. Ликвидировано три очага лесных пожаров на общей площади 44,6 га (Кугарчинский район, действовавший с 7 июля — 22,3 га; Зилаирский район — 11,5 га, действовавший с 9 июля; Белорецкий район — 10,8 га, действовавший с 9 июля). В регионе сейчас продолжают действовать пять очагов лесных пожаров на общей площади 132,3 га.                                                                                                                                                                                                                                                                                                                          2\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ..\n",
      " Купол на мечети «Ар-Рахим» в Уфе установят до конца мая Купол на мечети «Ар-Рахим» в башкирской столице планируют установить до конца мая. Об этом агентству «Башинформ» сообщил председатель Духовного управления мусульман республики Айнур Биргалин. По его словам, для монтажа на высоте более 100 метров потребуется башенный кран. Сейчас рабочие занимаются подготовкой площадки под кран. Сам купол в Уфу привезут ориентировочно в начале следующей недели. Напомним, старый купол одного из минаретов строящейся мечети сорвало шквалистым ветром 13 марта. По предварительным данным, разрушение произошло в результате инженерного просчета.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             1\n",
      " В МФЦ Башкирии теперь можно подать заявление на регистрацию брака Для этого пара может прийти в любой ближайший офис МФЦ. Подать заявление может и один из партнеров – в таком случае у него должен быть нотариально заверенный документ о желании пожениться от второй стороны. С собой необходимо взять паспорт, а также, если один из партнеров уже был в браке, понадобится свидетельство о расторжении прошлого союза.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1\n",
      " #ПостДобра Жительница Башкирии Елена Вавилкина дарит людям свои таланты и умения Героем проекта «Ярзам – время добрых дел» стала жительница села Ауструм Иглинского района Елена Вавилкина. Она работает старшим культорганизатором сельского Дома культуры – проводит в селе праздники, проводит конкурсы и игры. Еще Елена Геннадьевна – волонтер, она помогает многодетным семьям и пенсионерам, организовывая творческие мастер-классы и выезды в театры. - Я увидела, что пенсионерам сложнее на таких мастер-классах, чем детям. Некоторые пожилые люди уже не очень хорошо видят, а надо ведь небольшие кусочки ткани отмерить, потом ровно отрезать, — продолжает мастерица. — И я приноровилась — заранее делаю для пожилых участников все заготовки. Материалы для поделок женщина тоже предоставляет сама. А некоторые вещи с занятий передает многодетным семьям. А кукол, которых создает женщина, дарит своим гостям. Елена Вавилкина щедро дарит свои таланты односельчанам, заражает людей новыми идеями. К сожалению, пока ей приходится проводить мероприятия в крошечном помещении бывшего колхозного склада. Подробности истории                                                                                                                                                                                                                                                 1\n",
      "  Новая фабрика ZASPORT, официального экипировщика Олимпийской команды России, открыта в Ишимбае в особой экономической зоне «Алга». Фабрика ZASPORT оснащена современным оборудованием ведущих фирм-поставщиков. Общая численность персонала составляет 294 человека, объём готовой продукции - до 562 000 единиц в год. На площади 4552 кв.м. расположены раскройный, швейный, подготовительный и вышивальный цеха, отделы шелкотрафаретной печати, сублимации и трансферной печати, учебный класс, склады и другие помещения для обеспечения работы основного производства и комфортного пребывания сотрудников.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   1\n",
      " В Башкирии подросток сорвался со скалы в реку и утонул Страшная трагедия произошла сегодня на городском пруду в городе Белорецке. «Подросток, 2007 года рождения, поскользнулся с обрыва и упал в реку Белую. Его друзья самостоятельно извлекли его из воды и пытались оказать первую помощь», — рассказали «Башинформу» в госкомитете РБ по ЧС. Прибывшие на место спасатели и сотрудники скорой помощи пытались реанимировать подростка, но это не дало результатов.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              1\n",
      "Name: count, Length: 665, dtype: int64\n",
      "675\n",
      "-------------------------\n",
      "Train Max Sentence Length :894\n",
      "Train data len:540\n",
      "Class distributionCounter({1: 241, 2: 182, 0: 117})\n",
      "Valid data len:135\n",
      "Class distributionCounter({1: 61, 2: 45, 0: 29})\n"
     ]
    }
   ],
   "source": [
    "train_data= pd.read_excel(\"7.xlsx\")\n",
    "train_data.dropna(axis = 0, how ='any',inplace=True) \n",
    "train_data['Num_words_text'] = train_data['news'].apply(lambda x:len(str(x).split())) \n",
    "mask = train_data['Num_words_text'] >2\n",
    "train_data = train_data[mask]\n",
    "print('-------Train data--------')\n",
    "print(train_data['news'].value_counts())\n",
    "print(len(train_data))\n",
    "print('-------------------------')\n",
    "max_train_sentence_length  = train_data['Num_words_text'].max()\n",
    "\n",
    "\n",
    "train_data['news'] = train_data['news'].apply(remove_emoji)\n",
    "train_data['news'] = train_data['news'].apply(remove_url)\n",
    "train_data['news'] = train_data['news'].apply(clean_text)\n",
    "\n",
    "train_data['label'] = train_data['class'].apply(get_sentiment)\n",
    "print('Train Max Sentence Length :'+str(max_train_sentence_length))\n",
    "#print('Test Max Sentence Length :'+str(max_test_sentence_length))\n",
    "X_train, X_valid, Y_train, Y_valid= train_test_split(train_data['news'].tolist(),\\\n",
    "                                                      train_data['label'].tolist(),\\\n",
    "                                                      test_size=0.2,\n",
    "                                                      stratify = train_data['label'].tolist(),\n",
    "                                                      random_state=0)\n",
    "\n",
    "\n",
    "print('Train data len:'+str(len(X_train)))\n",
    "print('Class distribution'+str(Counter(Y_train)))\n",
    "\n",
    "\n",
    "print('Valid data len:'+str(len(X_valid)))\n",
    "print('Class distribution'+ str(Counter(Y_valid)))\n",
    "\n",
    "\n",
    "train_dat =list(zip(Y_train,X_train))\n",
    "valid_dat =list(zip(Y_valid,X_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cd3b938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_set = CustomDataset(X_train, Y_train, tokenizer)\n",
    "train_loader = DataLoader(train_set, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bba82351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fatik/anaconda3/envs/nlp/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "81a275c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "epochs=20\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer,\n",
    "                num_warmup_steps=0,\n",
    "                num_training_steps=len(train_loader) * epochs\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9c110a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "388dff9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "classifier = BertClassifier(\n",
    "        model_path='cointegrated/rubert-tiny',\n",
    "        tokenizer_path='cointegrated/rubert-tiny',\n",
    "        n_classes=3,\n",
    "        epochs=10,\n",
    "        model_save_path='/content/bert.pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ca10b93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fatik/anaconda3/envs/nlp/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_data= pd.read_excel(\"7.xlsx\")\n",
    "valid_data = pd.read_excel(\"7_valid.xlsx\")\n",
    "classifier.preparation(\n",
    "        X_train=list(train_data['news']),\n",
    "        y_train=list(train_data['class']),\n",
    "        X_valid=list(valid_data['news']),\n",
    "        y_valid=list(valid_data['class'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3e9ed54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#!CUDA_LAUNCH_BLOCKING=1\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m classifier\u001b[38;5;241m.\u001b[39mtrain()\n",
      "Cell \u001b[0;32mIn[63], line 101\u001b[0m, in \u001b[0;36mBertClassifier.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 101\u001b[0m     train_acc, train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit()\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m accuracy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    104\u001b[0m     val_acc, val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval()\n",
      "Cell \u001b[0;32mIn[63], line 46\u001b[0m, in \u001b[0;36mBertClassifier.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m correct_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader:\n\u001b[0;32m---> 46\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     47\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     48\u001b[0m     targets \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtargets\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "#!CUDA_LAUNCH_BLOCKING=1\n",
    "classifier.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead36e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7534ff64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d74ddb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8cbc9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d42011c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310b9e65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a8ed3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8a8f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddea3c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc93156a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fdd68c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5795b675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3f5538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9f6a52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b049b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1232d991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04a5873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b4ed61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90865c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f230787c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0754af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e778d39f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca53cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbb843c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cf23fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1f1749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1421ec14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce6a405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1807b4de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0edb938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed3e8b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e85346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cb91c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38fbc27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242006e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
