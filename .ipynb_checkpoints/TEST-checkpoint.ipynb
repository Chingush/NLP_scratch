{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1b69ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53eea533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def remove_url(text): \n",
    "    url_pattern  = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    return url_pattern.sub(r'', text)\n",
    " # converting return value from list to string\n",
    "\n",
    "\n",
    "\n",
    "def clean_text(text ): \n",
    "    delete_dict = {sp_character: '' for sp_character in string.punctuation} \n",
    "    delete_dict[' '] = ' ' \n",
    "    table = str.maketrans(delete_dict)\n",
    "    text1 = text.translate(table)\n",
    "    #print('cleaned:'+text1)\n",
    "    textArr= text1.split()\n",
    "    text2 = ' '.join([w for w in textArr if ( not w.isdigit() and  ( not w.isdigit() and len(w)>2))]) \n",
    "    \n",
    "    return text2.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91065372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(sentiment):\n",
    "    if sentiment == -1:\n",
    "        return 0\n",
    "    elif sentiment == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9af5c7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Train data--------\n",
      "news\n",
      " !Пожилого уфимца, отсидевшего за чужое преступление 13 лет, реабилитировали Фатхулла Исхаков отсидел 13 лет за чужое преступление и полвека добивался оправдания. Как сообщается в группе телепроекта [club187046624|ЧЕСТНО ГОВОРЯ | новости Уфы и Башкирии], впервые в истории страны дело с истёкшей 50 лет назад исковой давностью сначала было передано в Шестой кассационный суд, а затем и в Верховный суд России. Решение об отмене приговора 1959 года принял сегодня Верховный суд Российской Федерации. Конституционный суд России 21 декабря 2021 года разрешил судам в отдельных особых случаях пересматривать приговоры по новым обстоятельствам вопреки позиции прокурора. Соответствующее постановление в ответ на жалобу осужденного в 1959 году жителя Уфы Фатхуллы Исхакова опубликовали на официальном сайте суда. Уфимец был приговорен к лишению свободы по обвинению в покушении на убийство. 13 лет он провел в колонии. Мужчина утверждал, что ни в чем не виноват, и после освобождения десятки лет добивался отмены приговора. В 2012 году один из свидетелей признался в совершении преступления, за которое был осужден Исхаков. Много лет сохраняется неясность этого дела: прокуратура неоднократно прекращала его производство, суды по жалобам добивающегося реабилитации Исхакова с ней не соглашались, но и приговор заявителя не отменяли до сегодняшнего дня.    2\n",
      " Эльмира Диваева из Башкирии вышла в финал телешоу «Голос» Наша землячка Эльмира Диваева вышла в финала телешоу «Голос», сообщает Башинформ. Уроженка Стерлитамака исполнила песню «А на море белый песок» из репертура Жанны Фриске. Эльмира обошла соперниц из тройки своего наставника Владимира Преснякова еще на этапе зрительского голосования. Сам наставник также отдал ей половину своих голосов. Соперницами Эльмиры были Алина Бахшалиева из Саратова и Маргарита Багдасарян из Сочи.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      2\n",
      " Сотрудники ГИБДД Башкирии на трассе помогли дальнобойщику заменить колесо у большегруза Сотрудники ГИБДД Башкирии на федеральной трассе помогли дальнобойщику заменить колесо у большегруза. Как сообщили «Башинформу» в пресс-службе ведомства, во время профилактических мероприятий в Дюртюлинском районе на 1230 км М-7 «Волга» при объезде маршрута патрулирования автоинспекторы увидели стоящий на дороге большегруз Sitrak с проколотым задним колесом. «Сотрудники ГИБДД обеспечили безопасный проезд для других автомобилей, а затем помогли водителю заменить колесо. Автомобилист поблагодарил автоинспекторов за оказанную помощь, отметив, что он самостоятельно не справился бы», — подчеркнули в ведомстве.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          2\n",
      " Боец из Башкирии отдал свою жизнь ради победы над нацизмом Защитники Отечества выполняют важнейшую задачу и заслуживают, чтобы о них знала наша страна. Ефрейтор Данил Саматович Фаттахов — герой специальной военной операции. Боец родился 9 марта 1985 года. 2003 году окончил среднюю школу в Уфе. Затем проходил военную службу по призыву в войсках МЧС. Поступил в московский институт, одновременно работал водителем в полиции. 25 мая 2022 года заключил контракт на прохождение военной службы. 26 июня 2022 года героически погиб на территории Украины. Данил Саматович Фаттахов отдал свою жизнь ради победы над нацизмом. За мужество, отвагу и самоотверженность награжден орденом Мужества (посмертно).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             2\n",
      " «Обстановка только ухудшится»: Глава МЧС по Башкирии призвал граждан исключить разведение костров Начальник МЧС по Башкирии Марат Латыпов 11 июля на встрече с журналистами в ИА «Башинформ» сообщил о том, что в ближайшее время ситуация с пожарами в регионе может ухудшиться, так как прогнозируется усиление ветра, в частности, сегодня днем местами по республике ожидаются шквалистые порывы до 23-28 м/с. ??«Обстановка только ухудшится. Обращаюсь к жителям Башкирии! Исключите разведение костров, все, что подразумевает разведение огня. Нам и гроз хватает, которые провоцируют возгорания», — сказал Марат Латыпов. По его словам, за сутки зарегистрирован один очаг лесного пожара на площади 19,8 га в Гафурийском районе. Ликвидировано три очага лесных пожаров на общей площади 44,6 га (Кугарчинский район, действовавший с 7 июля — 22,3 га; Зилаирский район — 11,5 га, действовавший с 9 июля; Белорецкий район — 10,8 га, действовавший с 9 июля). В регионе сейчас продолжают действовать пять очагов лесных пожаров на общей площади 132,3 га.                                                                                                                                                                                                                                                                                                                          2\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ..\n",
      " Купол на мечети «Ар-Рахим» в Уфе установят до конца мая Купол на мечети «Ар-Рахим» в башкирской столице планируют установить до конца мая. Об этом агентству «Башинформ» сообщил председатель Духовного управления мусульман республики Айнур Биргалин. По его словам, для монтажа на высоте более 100 метров потребуется башенный кран. Сейчас рабочие занимаются подготовкой площадки под кран. Сам купол в Уфу привезут ориентировочно в начале следующей недели. Напомним, старый купол одного из минаретов строящейся мечети сорвало шквалистым ветром 13 марта. По предварительным данным, разрушение произошло в результате инженерного просчета.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             1\n",
      " В МФЦ Башкирии теперь можно подать заявление на регистрацию брака Для этого пара может прийти в любой ближайший офис МФЦ. Подать заявление может и один из партнеров – в таком случае у него должен быть нотариально заверенный документ о желании пожениться от второй стороны. С собой необходимо взять паспорт, а также, если один из партнеров уже был в браке, понадобится свидетельство о расторжении прошлого союза.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1\n",
      " #ПостДобра Жительница Башкирии Елена Вавилкина дарит людям свои таланты и умения Героем проекта «Ярзам – время добрых дел» стала жительница села Ауструм Иглинского района Елена Вавилкина. Она работает старшим культорганизатором сельского Дома культуры – проводит в селе праздники, проводит конкурсы и игры. Еще Елена Геннадьевна – волонтер, она помогает многодетным семьям и пенсионерам, организовывая творческие мастер-классы и выезды в театры. - Я увидела, что пенсионерам сложнее на таких мастер-классах, чем детям. Некоторые пожилые люди уже не очень хорошо видят, а надо ведь небольшие кусочки ткани отмерить, потом ровно отрезать, — продолжает мастерица. — И я приноровилась — заранее делаю для пожилых участников все заготовки. Материалы для поделок женщина тоже предоставляет сама. А некоторые вещи с занятий передает многодетным семьям. А кукол, которых создает женщина, дарит своим гостям. Елена Вавилкина щедро дарит свои таланты односельчанам, заражает людей новыми идеями. К сожалению, пока ей приходится проводить мероприятия в крошечном помещении бывшего колхозного склада. Подробности истории                                                                                                                                                                                                                                                 1\n",
      "  Новая фабрика ZASPORT, официального экипировщика Олимпийской команды России, открыта в Ишимбае в особой экономической зоне «Алга». Фабрика ZASPORT оснащена современным оборудованием ведущих фирм-поставщиков. Общая численность персонала составляет 294 человека, объём готовой продукции - до 562 000 единиц в год. На площади 4552 кв.м. расположены раскройный, швейный, подготовительный и вышивальный цеха, отделы шелкотрафаретной печати, сублимации и трансферной печати, учебный класс, склады и другие помещения для обеспечения работы основного производства и комфортного пребывания сотрудников.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   1\n",
      " В Башкирии подросток сорвался со скалы в реку и утонул Страшная трагедия произошла сегодня на городском пруду в городе Белорецке. «Подросток, 2007 года рождения, поскользнулся с обрыва и упал в реку Белую. Его друзья самостоятельно извлекли его из воды и пытались оказать первую помощь», — рассказали «Башинформу» в госкомитете РБ по ЧС. Прибывшие на место спасатели и сотрудники скорой помощи пытались реанимировать подростка, но это не дало результатов.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              1\n",
      "Name: count, Length: 665, dtype: int64\n",
      "675\n",
      "-------------------------\n",
      "Train Max Sentence Length :894\n"
     ]
    }
   ],
   "source": [
    "train_data= pd.read_excel(\"7.xlsx\")\n",
    "train_data.dropna(axis = 0, how ='any',inplace=True) \n",
    "train_data['Num_words_text'] = train_data['news'].apply(lambda x:len(str(x).split())) \n",
    "mask = train_data['Num_words_text'] >2\n",
    "train_data = train_data[mask]\n",
    "print('-------Train data--------')\n",
    "print(train_data['news'].value_counts())\n",
    "print(len(train_data))\n",
    "print('-------------------------')\n",
    "max_train_sentence_length  = train_data['Num_words_text'].max()\n",
    "\n",
    "\n",
    "train_data['news'] = train_data['news'].apply(remove_emoji)\n",
    "train_data['news'] = train_data['news'].apply(remove_url)\n",
    "train_data['news'] = train_data['news'].apply(clean_text)\n",
    "\n",
    "train_data['label'] = train_data['class'].apply(get_sentiment)\n",
    "print('Train Max Sentence Length :'+str(max_train_sentence_length))\n",
    "#print('Test Max Sentence Length :'+str(max_test_sentence_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20ee6d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>class</th>\n",
       "      <th>Num_words_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>кигинском районе башкирии откроют филиал парка...</td>\n",
       "      <td>1</td>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>многодетная мама уфы помогает малышам экстрема...</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>башкирия получила развитие туризма млн рублей ...</td>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>уфе состоится ночной забег июля уфе стартует н...</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>башкирию поступили обновленные 100рублевые бан...</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>писателю башкирии присудили престижную междуна...</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>самый известный таксист уфы собрал для онкобол...</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>уфимские предприниматели помогают ремонтироват...</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>глава башкирии подписал указ праздновании 100л...</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>уфимка мечтающая стать врачом сдала «химию» ба...</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news  class  Num_words_text  \\\n",
       "0  кигинском районе башкирии откроют филиал парка...      1             134   \n",
       "1  многодетная мама уфы помогает малышам экстрема...      1             158   \n",
       "2  башкирия получила развитие туризма млн рублей ...      1             126   \n",
       "3  уфе состоится ночной забег июля уфе стартует н...      1              78   \n",
       "4  башкирию поступили обновленные 100рублевые бан...      1              28   \n",
       "5  писателю башкирии присудили престижную междуна...      1              81   \n",
       "6  самый известный таксист уфы собрал для онкобол...      1             174   \n",
       "7  уфимские предприниматели помогают ремонтироват...      1             200   \n",
       "8  глава башкирии подписал указ праздновании 100л...      1              82   \n",
       "9  уфимка мечтающая стать врачом сдала «химию» ба...      1              68   \n",
       "\n",
       "   label  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  \n",
       "5      1  \n",
       "6      1  \n",
       "7      1  \n",
       "8      1  \n",
       "9      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddaf4561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data len:540\n",
      "Class distributionCounter({1: 241, 2: 182, 0: 117})\n",
      "Valid data len:135\n",
      "Class distributionCounter({1: 61, 2: 45, 0: 29})\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, Y_train, Y_valid= train_test_split(train_data['news'].tolist(),\\\n",
    "                                                      train_data['label'].tolist(),\\\n",
    "                                                      test_size=0.2,\n",
    "                                                      stratify = train_data['label'].tolist(),\n",
    "                                                      random_state=0)\n",
    "\n",
    "\n",
    "print('Train data len:'+str(len(X_train)))\n",
    "print('Class distribution'+str(Counter(Y_train)))\n",
    "\n",
    "\n",
    "print('Valid data len:'+str(len(X_valid)))\n",
    "print('Class distribution'+ str(Counter(Y_valid)))\n",
    "\n",
    "\n",
    "train_dat =list(zip(Y_train,X_train))\n",
    "valid_dat =list(zip(Y_valid,X_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a2e6257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fatik/anaconda3/envs/nlp/lib/python3.11/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /opt/conda/conda-bld/pytorch_1695392035891/work/c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device='CPU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69c50dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer('spacy', language='ru_core_news_sm')\n",
    "train_iter = train_dat\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a994dda",
   "metadata": {},
   "source": [
    "conda install -c conda-forge spacy-model-ru_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed829e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c23a3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 797]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline('Трогательное и нежное стихотворение о любви')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7343dab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "label_pipeline('1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cfda356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_label, _text) in batch:\n",
    "         label_list.append(label_pipeline(_label))\n",
    "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "         text_list.append(processed_text)\n",
    "         offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67ff8a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc1 = nn.Linear(embed_dim,64)\n",
    "        self.fc2 = nn.Linear(64,16)\n",
    "        self.fc3 = nn.Linear(16, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc1.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc1.bias.data.zero_()\n",
    "        self.fc2.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc2.bias.data.zero_()\n",
    "        self.fc3.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc3.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        x = F.relu(self.fc1(embedded))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "926a2ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "664e0980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "train_iter1 = train_dat\n",
    "num_class = len(set([label for (label, text) in train_iter1]))\n",
    "print(num_class)\n",
    "vocab_size = len(vocab)\n",
    "emsize = 128\n",
    "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6692983a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        #print(1)\n",
    "        optimizer.zero_grad()\n",
    "        #print(2)\n",
    "        predited_label = model(text, offsets)\n",
    "        #print(3)\n",
    "        loss = criterion(predited_label, label)\n",
    "        #print(4)\n",
    "        loss.backward()\n",
    "        #print(5)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        #print(6)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predited_label = model(text, offsets)\n",
    "            loss = criterion(predited_label, label)\n",
    "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a5a97a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Could not run 'aten::_foreach_norm.Scalar' with arguments from the 'SparseCPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_foreach_norm.Scalar' is only available for these backends: [CPU, CUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nCPU: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/build/aten/src/ATen/RegisterCPU.cpp:31188 [kernel]\nCUDA: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/build/aten/src/ATen/RegisterCUDA.cpp:44143 [kernel]\nBackendSelect: fallthrough registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/core/PythonFallbackKernel.cpp:153 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/functorch/DynamicLayer.cpp:498 [backend fallback]\nFunctionalize: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/FunctionalizeFallbackKernel.cpp:290 [backend fallback]\nNamed: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/native/NegateFallback.cpp:19 [backend fallback]\nZeroTensor: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/core/VariableFallbackKernel.cpp:86 [backend fallback]\nAutogradOther: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradCPU: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradCUDA: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradHIP: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradXLA: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradMPS: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradIPU: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradXPU: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradHPU: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradVE: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradLazy: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradMTIA: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradPrivateUse1: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradPrivateUse2: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradPrivateUse3: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradMeta: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradNestedTensor: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nTracer: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/TraceType_2.cpp:17079 [kernel]\nAutocastCPU: fallthrough registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/autocast_mode.cpp:382 [backend fallback]\nAutocastCUDA: fallthrough registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/autocast_mode.cpp:249 [backend fallback]\nFuncTorchBatched: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:710 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/functorch/TensorWrapper.cpp:203 [backend fallback]\nPythonTLSSnapshot: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/core/PythonFallbackKernel.cpp:161 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/functorch/DynamicLayer.cpp:494 [backend fallback]\nPreDispatch: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/core/PythonFallbackKernel.cpp:165 [backend fallback]\nPythonDispatcher: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/core/PythonFallbackKernel.cpp:157 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     26\u001b[0m     epoch_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 27\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     accu_val \u001b[38;5;241m=\u001b[39m evaluate(valid_dataloader)\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m total_accu \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m total_accu \u001b[38;5;241m>\u001b[39m accu_val:\n",
      "Cell \u001b[0;32mIn[39], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader)\u001b[0m\n\u001b[1;32m     17\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#print(5)\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#print(6)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.11/site-packages/torch/nn/utils/clip_grad.py:55\u001b[0m, in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ((device, _), ([grads], _)) \u001b[38;5;129;01min\u001b[39;00m grouped_grads\u001b[38;5;241m.\u001b[39mitems():  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (foreach \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m foreach) \u001b[38;5;129;01mand\u001b[39;00m _has_foreach_support(grads, device\u001b[38;5;241m=\u001b[39mdevice):\n\u001b[0;32m---> 55\u001b[0m         norms\u001b[38;5;241m.\u001b[39mextend(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m foreach:\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach=True was passed, but can\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt use the foreach API on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tensors\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Could not run 'aten::_foreach_norm.Scalar' with arguments from the 'SparseCPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_foreach_norm.Scalar' is only available for these backends: [CPU, CUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nCPU: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/build/aten/src/ATen/RegisterCPU.cpp:31188 [kernel]\nCUDA: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/build/aten/src/ATen/RegisterCUDA.cpp:44143 [kernel]\nBackendSelect: fallthrough registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/core/PythonFallbackKernel.cpp:153 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/functorch/DynamicLayer.cpp:498 [backend fallback]\nFunctionalize: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/FunctionalizeFallbackKernel.cpp:290 [backend fallback]\nNamed: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/native/NegateFallback.cpp:19 [backend fallback]\nZeroTensor: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/core/VariableFallbackKernel.cpp:86 [backend fallback]\nAutogradOther: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradCPU: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradCUDA: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradHIP: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradXLA: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradMPS: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradIPU: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradXPU: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradHPU: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradVE: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradLazy: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradMTIA: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradPrivateUse1: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradPrivateUse2: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradPrivateUse3: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradMeta: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nAutogradNestedTensor: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/VariableType_2.cpp:18610 [autograd kernel]\nTracer: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/autograd/generated/TraceType_2.cpp:17079 [kernel]\nAutocastCPU: fallthrough registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/autocast_mode.cpp:382 [backend fallback]\nAutocastCUDA: fallthrough registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/autocast_mode.cpp:249 [backend fallback]\nFuncTorchBatched: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:710 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/functorch/TensorWrapper.cpp:203 [backend fallback]\nPythonTLSSnapshot: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/core/PythonFallbackKernel.cpp:161 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/functorch/DynamicLayer.cpp:494 [backend fallback]\nPreDispatch: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/core/PythonFallbackKernel.cpp:165 [backend fallback]\nPythonDispatcher: registered at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/core/PythonFallbackKernel.cpp:157 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "# Hyperparameters\n",
    "EPOCHS = 20 # epoch\n",
    "LR =10  # learning rate\n",
    "BATCH_SIZE = 4 # batch size for training\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None\n",
    "\n",
    "train_iter2 = train_dat\n",
    "valid_iter2= valid_dat\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_iter2, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(valid_iter2, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        total_accu = accu_val\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad69905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9258162f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8459194f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa093e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a31c3b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df90bd7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4af2c16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40864b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18720db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3604c69d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae71a18b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b75cc74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385867c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee335ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c8f7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce27d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571e2b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41f70d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bdbd82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3407d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bdef11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e3bd5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
